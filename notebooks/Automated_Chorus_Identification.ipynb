{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8b024bf7-9c0e-4df8-8774-3fb52ad361ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import os\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import gzip\n",
    "\n",
    "warnings.filterwarnings('ignore', category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d8e4a60d-7c0d-462b-80de-2c3f29414a4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_key_invariant(chromagram):\n",
    "    \"\"\"Returns a key-invariant chromagram.\"\"\"\n",
    "    maj_profile = np.array([6.35, 2.23, 3.48, 2.33, 4.38, 4.09, 2.52, 5.19, 2.39, 3.66, 2.29, 2.88])\n",
    "    min_profile = np.array([6.33, 2.68, 3.52, 5.38, 2.60, 3.53, 2.54, 4.75, 3.98, 2.69, 3.34, 3.17])\n",
    "    avg_chroma = np.mean(chromagram, axis=1)\n",
    "    maj_corrs = np.correlate(avg_chroma, maj_profile, mode='same')\n",
    "    min_corrs = np.correlate(avg_chroma, min_profile, mode='same')\n",
    "    key_shift = np.argmax(np.concatenate((maj_corrs, min_corrs))) % 12\n",
    "    return np.roll(chromagram, -key_shift, axis=0)\n",
    "\n",
    "def segment_by_beats(feature_array, beat_frames):\n",
    "    \"\"\"Segments a 2D array of audio features by beat frames.\"\"\"\n",
    "    beat_frames = np.append(beat_frames, feature_array.shape[1])\n",
    "    return [feature_array[:, beat_frames[i]:beat_frames[i + 1]] for i in range(len(beat_frames) - 1)]\n",
    "\n",
    "def map_labels_to_beats(df_labels, beat_times):\n",
    "    \"\"\"Map chorus labels to beat-synced data.\"\"\"\n",
    "    labels = np.zeros(len(beat_times) - 1)\n",
    "    for _, row in df_labels.iterrows():\n",
    "        indices = np.where((beat_times[:-1] >= row['start_time']) & (beat_times[:-1] < row['end_time']))[0]\n",
    "        labels[indices] = 1 if row['label'] == 'chorus' else 0\n",
    "    return labels\n",
    "\n",
    "def save_compressed_pickle(file_path, data):\n",
    "    \"\"\"Save data to a compressed pickle file.\"\"\"\n",
    "    with gzip.open(file_path, 'wb') as f:\n",
    "        pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7b62ff02-f3b5-4e81-8bb5-5a87e02f3906",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...: 100%|██████████| 332/332 [1:06:43<00:00, 12.06s/it]\n"
     ]
    }
   ],
   "source": [
    "# Ensure required directories exist\n",
    "os.makedirs(\"../data/pkl/segments\", exist_ok=True)\n",
    "os.makedirs(\"../data/pkl/labels\", exist_ok=True)\n",
    "\n",
    "# Constants\n",
    "df = pd.read_csv('../data/dataframes/clean_labeled.csv')\n",
    "TARGET_SR = 12000 # Target sample rate chosen to be 1/4 of the original 48kHz.\n",
    "HOP_LENGTH = 128  # Hop length for short-time Fourier transform. Hop length of 128 at 12kHz gives a similar frame rate to a hop length of 512 at 48kHz.\n",
    "\n",
    "# Process each song in the dataset\n",
    "for song_id in tqdm(df['SongID'].unique(), desc=\"Processing...\"):\n",
    "    # Load the audio file\n",
    "    audio_path = f'../data/audio_files/processed/{song_id}.mp3'\n",
    "    y, _ = librosa.load(audio_path, sr=TARGET_SR)\n",
    "    \n",
    "    # Harmonic-percussive source separation\n",
    "    y_harm, y_perc = librosa.effects.hpss(y)\n",
    "    \n",
    "    # Compute onset envelope from the percussive component\n",
    "    onset_env = librosa.onset.onset_strength(y=y_perc, sr=TARGET_SR, hop_length=HOP_LENGTH)\n",
    "\n",
    "    # Beat tracking\n",
    "    _, beats = librosa.beat.beat_track(onset_envelope=onset_env, sr=TARGET_SR, hop_length=HOP_LENGTH)\n",
    "    beat_times = librosa.frames_to_time(beats, sr=TARGET_SR, hop_length=HOP_LENGTH)\n",
    "    \n",
    "    # Map labels to beats\n",
    "    df_labels = df[df['SongID'] == song_id][['start_time', 'end_time', 'label']]\n",
    "    labels = map_labels_to_beats(df_labels, beat_times)\n",
    "    \n",
    "    # Compute RMS energy from spectrogram to give a more accurate representation of energy over time because its frames can be windowed\n",
    "    S = np.abs(librosa.stft(y, hop_length=HOP_LENGTH))\n",
    "    rms = librosa.feature.rms(S=S)\n",
    "    \n",
    "    # Compute Mel Spectrogram and decompose into 4 components (4 chosen from EDA)\n",
    "    mel = librosa.feature.melspectrogram(y=y, sr=TARGET_SR, n_mels=128, hop_length=HOP_LENGTH)\n",
    "    mel_acts = librosa.decompose.decompose(mel, n_components=4, sort=True)[1]\n",
    "    \n",
    "    # Compute chromagram, make it key invariant, and decompose \n",
    "    chromagram = librosa.feature.chroma_cqt(y=y_harm, sr=TARGET_SR, hop_length=HOP_LENGTH)\n",
    "    chroma_ki = make_key_invariant(chromagram)\n",
    "    chroma_acts = librosa.decompose.decompose(chroma_ki, n_components=3, sort=True)[1]\n",
    "    \n",
    "    # Compute tempogram, ensure non-negative, and decompose \n",
    "    tempogram = np.clip(librosa.feature.tempogram(onset_envelope=onset_env, sr=TARGET_SR, hop_length=HOP_LENGTH), 0, None)\n",
    "    tempogram_acts = librosa.decompose.decompose(tempogram, n_components=3, sort=True)[1]\n",
    "    \n",
    "    # Compute MFCCs\n",
    "    mfccs = librosa.feature.mfcc(y=y, sr=TARGET_SR, n_mfcc=13, hop_length=HOP_LENGTH)\n",
    "    \n",
    "    # Standardize features, stack, and segment by beats\n",
    "    features = [rms, mel_acts, chroma_acts, tempogram_acts, mfccs]\n",
    "    standardized_features = [StandardScaler().fit_transform(feature.T).T for feature in features]\n",
    "    concat_features = np.vstack(standardized_features)\n",
    "    segments = segment_by_beats(concat_features, beats)\n",
    "\n",
    "    # Save results with compression\n",
    "    save_compressed_pickle(f\"../data/pkl/segments/{song_id}_beats.pkl.gz\", segments)\n",
    "    save_compressed_pickle(f\"../data/pkl/labels/{song_id}_labels.pkl.gz\", labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "12048a72-9d59-4888-930d-dc48bc31cee2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d6fc1a03-2095-4947-9164-3f1d66dcbbf8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1a20f1f755c439fb72dab173eacc148",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Unloading data...beep boop I am a robot:   0%|          | 0/332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize dictionaries to hold the segments and labels\n",
    "beat_segments, beat_labels = {}, {}\n",
    "\n",
    "# Define the base paths for the segments and labels directories\n",
    "segments_base_path = \"../data/pkl/segments/\"\n",
    "labels_base_path = \"../data/pkl/labels/\"\n",
    "\n",
    "for song_id in tqdm(df['SongID'].unique(), desc=\"Unloading data...beep boop I am a robot\"):\n",
    "    # Construct the full file paths for the segments and labels\n",
    "    segments_path = os.path.join(segments_base_path, f\"{song_id}_beats.pkl.gz\")\n",
    "    labels_path = os.path.join(labels_base_path, f\"{song_id}_labels.pkl.gz\")\n",
    "    \n",
    "    # Load the segments\n",
    "    with gzip.open(segments_path, 'rb') as f:\n",
    "        beat_segments[song_id] = pickle.load(f)\n",
    "    \n",
    "    # Load the labels\n",
    "    with gzip.open(labels_path, 'rb') as f:\n",
    "        beat_labels[song_id] = pickle.load(f)\n",
    "        \n",
    "# Convert dictionaries to lists for further processing\n",
    "X = list(beat_segments.values())\n",
    "y = list(beat_labels.values())\n",
    "\n",
    "# Split the data in 70/15/15 train/val/test splits\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf565fae-a72d-4180-a5fb-2c493c1862c5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### In progress.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47944f0-323a-485d-8648-af3893184c48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_batches_and_pad(sequences, labels, batch_size, padding_value=-1, add_pos_encoding=False):\n",
    "    \"\"\"Create and pad batches of sequences and labels.\"\"\"\n",
    "    padded_batches = []\n",
    "    for i in range(0, len(sequences), batch_size):\n",
    "        batch_sequences = sequences[i:i + batch_size]\n",
    "        batch_labels = labels[i:i + batch_size]\n",
    "        \n",
    "        # Pad sequences and labels\n",
    "        padded_sequences = pad_sequences(batch_sequences, padding='post', value=padding_value)\n",
    "        padded_labels = pad_sequences(batch_labels, padding='post', value=padding_value)\n",
    "        \n",
    "        if add_pos_encoding:\n",
    "            padded_sequences = add_positional_encoding(padded_sequences)\n",
    "        \n",
    "        padded_batches.append((padded_sequences, padded_labels))\n",
    "    \n",
    "    return padded_batches\n",
    "\n",
    "\n",
    "def custom_binary_crossentropy(y_true, y_pred):\n",
    "    \"\"\"Custom binary cross-entropy loss to handle -1 labels, which are used for padding and should be ignored during loss calculation.\"\"\"\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    bce = tf.keras.backend.binary_crossentropy(y_true, y_pred)\n",
    "    mask = tf.cast(tf.not_equal(y_true, -1), tf.float32)\n",
    "    loss = bce * mask\n",
    "    return tf.reduce_sum(loss) / tf.reduce_sum(mask)\n",
    "\n",
    "def custom_accuracy(y_true, y_pred):\n",
    "    \"\"\"Custom accuracy metric to handle -1 labels, which are used for padding and should be ignored during accuracy calculation.\"\"\"\n",
    "    mask = tf.cast(tf.not_equal(y_true, -1), tf.float32)\n",
    "    correct_predictions = tf.equal(tf.cast(tf.round(y_pred), tf.float32), y_true)\n",
    "    masked_correct_predictions = tf.cast(correct_predictions, tf.float32) * mask\n",
    "    accuracy = tf.reduce_sum(masked_correct_predictions) / tf.reduce_sum(mask)\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def compile_model(max_frames, max_freq_bins, n_features, custom_binary_crossentropy, custom_accuracy, max_beats):\n",
    "    \"\"\"\n",
    "    Define and compile a CNN model with considerations for environmental sound classification.\n",
    "    \"\"\"\n",
    "    frame_input = layers.Input(shape=(max_frames, max_freq_bins, n_features))\n",
    "    \n",
    "    # Assuming Mx3 filter means spanning the entire frequency bins with a width of 3.\n",
    "    conv1 = layers.Conv2D(filters=128, kernel_size=(max_freq_bins, 3), activation='relu', padding='same')(frame_input)\n",
    "    pool1 = layers.MaxPooling2D(pool_size=(4, 4), padding='same')(conv1)\n",
    "    dropout1 = layers.Dropout(0.5)(pool1)  # Applying 50% dropout after pooling\n",
    "    \n",
    "    conv2 = layers.Conv2D(filters=256, kernel_size=(1, 3), activation='relu', padding='same')(dropout1) # Changed to 1x3 to not reduce the frequency dimension further\n",
    "    pool2 = layers.MaxPooling2D(pool_size=(4, 4), padding='same')(conv2)\n",
    "    dropout2 = layers.Dropout(0.5)(pool2)  # Applying 50% dropout after pooling\n",
    "    \n",
    "    conv3 = layers.Conv2D(filters=256, kernel_size=(1, 3), activation='relu', padding='same')(dropout2) # Changed to 1x3 for consistency\n",
    "    pool3 = layers.MaxPooling2D(pool_size=(4, 4), padding='same')(conv3)\n",
    "    dropout3 = layers.Dropout(0.5)(pool3)  # Applying 50% dropout after pooling\n",
    "    \n",
    "    frame_features = layers.Flatten()(dropout3)\n",
    "    frame_feature_model = models.Model(inputs=frame_input, outputs=frame_features)\n",
    "\n",
    "    measure_input = layers.Input(shape=(max_beats, max_frames, max_freq_bins, n_features))\n",
    "    time_distributed = layers.TimeDistributed(frame_feature_model)(measure_input)\n",
    "    masking_layer = layers.Masking(mask_value=-1)(time_distributed)\n",
    "    lstm_out = layers.Bidirectional(layers.LSTM(256, return_sequences=True))(masking_layer)\n",
    "    output = layers.TimeDistributed(layers.Dense(1, activation='sigmoid'))(lstm_out)\n",
    "    model = models.Model(inputs=measure_input, outputs=output)\n",
    "    model.compile(optimizer='adam', loss=custom_binary_crossentropy, metrics=[custom_accuracy])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5596ea8c-e986-4d12-9f10-006064e55385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5-fold cross-validation with stratified splitting, batching, and positional encoding\n",
    "def get_positional_encoding(max_len, d_model):\n",
    "    \"\"\"Generates sinusoidal positional encodings.\"\"\"\n",
    "    pos = np.arange(max_len)[:, np.newaxis]\n",
    "    i = np.arange(d_model // 2)[np.newaxis, :]\n",
    "    angles = pos / np.power(10000, (2 * i) / d_model)\n",
    "    sin_enc = np.sin(angles)\n",
    "    cos_enc = np.cos(angles)\n",
    "    encoding = np.concatenate([sin_enc, cos_enc[:, :d_model // 2]], axis=-1)\n",
    "    return encoding\n",
    "\n",
    "def apply_positional_encoding(features, pos_encoding):\n",
    "    \"\"\"Applies positional encoding to the input features.\"\"\"\n",
    "    return features + pos_encoding[:features.shape[1], :]\n",
    "\n",
    "\n",
    "def run_cross_validation(n_splits=5, batch_size=32, feat_dim=128):\n",
    "    \"\"\"Runs cross-validation with stratified splitting, batching, and positional encoding.\"\"\"\n",
    "    song_ids = df['SongID'].unique()\n",
    "    all_labels = np.concatenate([padded_beat_labels[id] for id in song_ids])\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    fold_scores = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(cv.split(song_ids, all_labels), start=1):\n",
    "        print(f\"Fold {fold}/{n_splits}\")\n",
    "\n",
    "        train_ids, val_ids = song_ids[train_idx], song_ids[val_idx]\n",
    "        train_batches = [(get_batch_segments(ids, padded_beat_segments, padded_beat_labels, feat_dim), \n",
    "                          get_batch_labels(ids, padded_beat_labels)) for ids in create_batches(train_ids, batch_size)]\n",
    "        val_batches = [(get_batch_segments(ids, padded_beat_segments, padded_beat_labels, feat_dim), \n",
    "                        get_batch_labels(ids, padded_beat_labels)) for ids in create_batches(val_ids, batch_size)]\n",
    "\n",
    "        # Train and evaluate model\n",
    "        model = train_model(train_batches)\n",
    "        val_score = evaluate_model(model, val_batches)\n",
    "        fold_scores.append(val_score)\n",
    "\n",
    "    avg_score = np.mean(fold_scores)\n",
    "    print(f\"Average Cross-Validation Score: {avg_score}\")\n",
    "\n",
    "def train_model(train_batches):\n",
    "    # Define the directories for checkpoints and models\n",
    "    checkpoint_dir = os.path.join('..', 'checkpoints', 'CRNN')\n",
    "    model_dir = os.path.join('..', 'models', 'CRNN')\n",
    "\n",
    "    # Ensure the checkpoint and model directories exist\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "    # Define the checkpoint path for the best model\n",
    "    best_model_filepath = os.path.join(model_dir, 'best_model.h5')\n",
    "\n",
    "    callbacks = [\n",
    "        ModelCheckpoint(\n",
    "            filepath=best_model_filepath,\n",
    "            save_weights_only=False,\n",
    "            monitor='val_custom_accuracy',  # Use 'val_custom_accuracy' for validation custom accuracy\n",
    "            mode='max',\n",
    "            save_best_only=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        EarlyStopping(\n",
    "            monitor='val_loss',  \n",
    "            patience=3,\n",
    "            verbose=1,\n",
    "            restore_best_weights=True\n",
    "        ),\n",
    "        ReduceLROnPlateau(\n",
    "            monitor='val_loss',  \n",
    "            factor=0.1,\n",
    "            patience=2,\n",
    "            verbose=1,\n",
    "            min_delta=0.0001,\n",
    "            min_lr=0.00001\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # Train the model with the simplified callbacks list\n",
    "    history = model.fit(\n",
    "        train_dataset,\n",
    "        epochs=10,\n",
    "        validation_data=val_dataset,\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "\n",
    "def evaluate_model(model, val_batches):\n",
    "    # Implement model evaluation here\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21052a43-7191-4e43-aba1-7f65f54ec21e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1db4149-9754-4c22-8716-9e1d44c6f349",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f39cba-b94e-4b70-af11-5f6818ed106b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
