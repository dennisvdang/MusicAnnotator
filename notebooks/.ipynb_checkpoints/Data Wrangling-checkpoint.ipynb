{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f063559a",
   "metadata": {},
   "source": [
    "# Data Wrangling for MusicAnnotator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9f3686",
   "metadata": {},
   "source": [
    "This Jupyter Notebook is intended for the data wrangling tasks required in the Music Annotator Project. We'll import necessary libraries, define constants, create utility functions, merge data sources, clean/process/explore the data, and save the results.\n",
    "\n",
    "Things to consider:\n",
    "\n",
    "-Filter out annotation data with low inter-rater reliability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08dccb15",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2185f407",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "from ydata_profiling import ProfileReport\n",
    "from IPython.display import IFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639cbb1c",
   "metadata": {},
   "source": [
    "## Define Constants and Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddd2a98b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Define the path to the directories\n",
    "annotations_path = '../data/annotations'\n",
    "mp3_path = '../data/external/transformed_audio'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb71037c",
   "metadata": {},
   "source": [
    "## Parse Annotations and Extract Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a7b6c8a6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  song_id annotator     timestamp     function\n",
      "0    1000         1           0.0      Silence\n",
      "1    1000         1   0.049342403        Intro\n",
      "2    1000         1   8.848639455  no_function\n",
      "3    1000         1  23.935464852        Verse\n",
      "4    1000         1  35.661428571  no_function\n",
      "song_id      571\n",
      "annotator      2\n",
      "dtype: int64\n",
      "song_id    13116\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Function to extract data from annotation text files\n",
    "def extract_data(file_path):\n",
    "    \"\"\"\n",
    "    Reads tab or space separated data from a file.\n",
    "    Args:\n",
    "        file_path (str): The path of the file to read from.\n",
    "    Returns:\n",
    "        list: A list of lists with the stripped and split lines of the file.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r') as file:\n",
    "        return [line.strip().split() for line in file if line.strip()]\n",
    "\n",
    "# Get a list of all mp3 filenames without extensions\n",
    "mp3_files = {os.path.splitext(file)[0] for file in os.listdir(mp3_path) if file.endswith('.mp3')}\n",
    "\n",
    "# Initialize a list to store data\n",
    "data_list = []\n",
    "\n",
    "# Iterate through all song_id directories in the annotations directory\n",
    "for song_id in os.listdir(annotations_path):\n",
    "    parsed_path = os.path.join(annotations_path, song_id, 'parsed')\n",
    "    if os.path.isdir(parsed_path) and song_id in mp3_files:\n",
    "        function_files = glob.glob(os.path.join(parsed_path, \"*_functions.txt\"))\n",
    "        song_data = [extract_data(file_path) for file_path in function_files]\n",
    "        \n",
    "        # Flatten the list of lists and add chorus information\n",
    "        for file_path in function_files:\n",
    "            # Extract the annotator's number from the filename\n",
    "            # Assuming the pattern is 'textfileN_functions.txt' where N is the annotator number\n",
    "            file_name = os.path.basename(file_path)\n",
    "            annotator = file_name.split('textfile')[-1].split('_')[0]\n",
    "            annotator_data = extract_data(file_path)\n",
    "            for timestamp, function in annotator_data:\n",
    "                data_list.append({\n",
    "                    'song_id': song_id,\n",
    "                    'annotator': annotator,\n",
    "                    'timestamp': timestamp,\n",
    "                    'function': function\n",
    "                })\n",
    "\n",
    "# Create a DataFrame from the collected data\n",
    "df = pd.DataFrame(data_list)\n",
    "# Reorder columns if needed and reset index\n",
    "df = df[['song_id', 'annotator', 'timestamp', 'function']]\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(df.head())\n",
    "print(df[['song_id','annotator']].nunique())\n",
    "print(df[['song_id']].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1d529bc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "function       \n",
       "Verse              2025\n",
       "Chorus             1819\n",
       "Solo               1426\n",
       "no_function        1412\n",
       "Silence            1343\n",
       "End                 904\n",
       "Intro               790\n",
       "Outro               500\n",
       "Interlude           490\n",
       "Instrumental        469\n",
       "Transition          365\n",
       "Bridge              345\n",
       "Theme               308\n",
       "Head                220\n",
       "Pre-Chorus          171\n",
       "silence             131\n",
       "Coda                111\n",
       "Main_Theme           74\n",
       "post-chorus          45\n",
       "Pre-Verse            24\n",
       "Fade-out             23\n",
       "break                22\n",
       "applause             22\n",
       "Secondary_Theme      21\n",
       "stage_sounds          9\n",
       "groove                6\n",
       "Development           4\n",
       "dialog                4\n",
       "tag                   3\n",
       "voice                 3\n",
       "spoken_voice          3\n",
       "post-verse            2\n",
       "response              2\n",
       "stage_speaking        2\n",
       "Recap                 2\n",
       "banjo                 2\n",
       "crowd_sounds          2\n",
       "variation_2           2\n",
       "Secondary_theme       2\n",
       "variation             1\n",
       "variation_1           1\n",
       "&pause                1\n",
       "spoken                1\n",
       "out                   1\n",
       "count-in              1\n",
       "build                 1\n",
       "w/dialog              1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking if there are any other functions we should account for\n",
    "df[['function']].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b9892f",
   "metadata": {},
   "source": [
    "## Extract Choruses Start & End Times + Calculate Duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "afb0c6ee",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  song_id annotator  chorus_start  chorus_end  chorus_duration\n",
      "0    1003         1    107.144059  118.560272        11.416213\n",
      "1    1003         1    153.137029  176.392086        23.255057\n",
      "2    1003         2     89.722358  118.502698        28.780340\n",
      "3    1003         2    210.783991  239.428345        28.644354\n",
      "4    1004         1     74.257415  112.743107        38.485692 \n",
      "\n",
      "Number of unique songs: 337 \n",
      "\n",
      "Total number of choruses: 1448\n"
     ]
    }
   ],
   "source": [
    "def extract_chorus_times_with_duration(df):\n",
    "    \"\"\"\n",
    "    Extracts choruses and their durations from a DataFrame and excludes songs where there are two annotators\n",
    "    but not both have annotated choruses.\n",
    "    \n",
    "    Args:\n",
    "        df (DataFrame): The DataFrame to process.\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: A DataFrame with choruses and their start, end, and duration.\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert 'timestamp' column to numeric (float) within the function to avoid altering the original DataFrame\n",
    "    df['timestamp'] = pd.to_numeric(df['timestamp'], errors='coerce')\n",
    "\n",
    "    # Create a DataFrame to hold chorus data\n",
    "    chorus_data_list = []\n",
    "\n",
    "    # Process each song and annotator group\n",
    "    for (song_id, annotator), group in df.groupby(['song_id', 'annotator']):\n",
    "        group = group.sort_values('timestamp').reset_index(drop=True)\n",
    "        chorus_start = None\n",
    "        for i, row in enumerate(group.itertuples()):\n",
    "            if 'Chorus' in row.function and chorus_start is None:\n",
    "                chorus_start = row.timestamp  # 'timestamp' is already a float after conversion\n",
    "            elif chorus_start is not None and row.function not in ('Chorus'):\n",
    "                chorus_end = row.timestamp\n",
    "                chorus_duration = chorus_end - chorus_start\n",
    "                if chorus_duration >= 3:\n",
    "                    chorus_data_list.append({\n",
    "                        'song_id': song_id,\n",
    "                        'annotator': annotator,\n",
    "                        'chorus_start': chorus_start,\n",
    "                        'chorus_end': chorus_end,\n",
    "                        'chorus_duration': chorus_duration\n",
    "                    })\n",
    "                chorus_start = None  # Reset the chorus start for the next chorus\n",
    "            # If it's the last row and we're still in a chorus, we take the end as the last timestamp\n",
    "            if chorus_start is not None and i == len(group) - 1:\n",
    "                chorus_end = row.timestamp\n",
    "                chorus_duration = chorus_end - chorus_start\n",
    "                if chorus_duration >= 3:\n",
    "                    chorus_data_list.append({\n",
    "                        'song_id': song_id,\n",
    "                        'annotator': annotator,\n",
    "                        'chorus_start': chorus_start,\n",
    "                        'chorus_end': chorus_end,\n",
    "                        'chorus_duration': chorus_duration\n",
    "                    })\n",
    "\n",
    "    # Create DataFrame from the list of chorus data\n",
    "    chorus_df = pd.DataFrame(chorus_data_list)\n",
    "\n",
    "    # Count the number of unique annotators per song\n",
    "    annotator_counts = df.groupby('song_id')['annotator'].nunique()\n",
    "\n",
    "    # Identify songs that have two annotators\n",
    "    two_annotator_songs = annotator_counts[annotator_counts == 2].index\n",
    "\n",
    "    # Filter out songs that have two annotators but not both have annotated choruses\n",
    "    valid_songs = []\n",
    "    for song_id in two_annotator_songs:\n",
    "        annotator_chorus_counts = chorus_df[chorus_df['song_id'] == song_id]['annotator'].nunique()\n",
    "        # If both annotators have choruses, include the song_id\n",
    "        if annotator_chorus_counts == 2:\n",
    "            valid_songs.append(song_id)\n",
    "    \n",
    "    # Include songs that have only one annotator\n",
    "    valid_songs.extend(annotator_counts[annotator_counts == 1].index)\n",
    "\n",
    "    # Filter the chorus_df to only include valid songs\n",
    "    filtered_chorus_df = chorus_df[chorus_df['song_id'].isin(valid_songs)]\n",
    "\n",
    "    return filtered_chorus_df\n",
    "\n",
    "# Extract chorus times and create a new DataFrame with durations\n",
    "chorus_df_dur = extract_chorus_times_with_duration(df)\n",
    "print(chorus_df_dur.head(), \"\\n\")\n",
    "print('Number of unique songs:', chorus_df_dur['song_id'].nunique(), \"\\n\")\n",
    "print('Total number of choruses:', chorus_df_dur.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "53eea65c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_id</th>\n",
       "      <th>annotator</th>\n",
       "      <th>chorus_start</th>\n",
       "      <th>chorus_end</th>\n",
       "      <th>chorus_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>1092</td>\n",
       "      <td>1</td>\n",
       "      <td>39.352906</td>\n",
       "      <td>108.064000</td>\n",
       "      <td>68.711094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>1092</td>\n",
       "      <td>2</td>\n",
       "      <td>132.128938</td>\n",
       "      <td>207.033281</td>\n",
       "      <td>74.904344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>1112</td>\n",
       "      <td>1</td>\n",
       "      <td>160.276825</td>\n",
       "      <td>229.602449</td>\n",
       "      <td>69.325624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>1131</td>\n",
       "      <td>1</td>\n",
       "      <td>207.403991</td>\n",
       "      <td>273.851429</td>\n",
       "      <td>66.447438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>1132</td>\n",
       "      <td>1</td>\n",
       "      <td>150.401088</td>\n",
       "      <td>212.810884</td>\n",
       "      <td>62.409796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>1135</td>\n",
       "      <td>1</td>\n",
       "      <td>218.928186</td>\n",
       "      <td>285.362290</td>\n",
       "      <td>66.434104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>1146</td>\n",
       "      <td>1</td>\n",
       "      <td>251.634218</td>\n",
       "      <td>331.775601</td>\n",
       "      <td>80.141383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>1190</td>\n",
       "      <td>1</td>\n",
       "      <td>113.631565</td>\n",
       "      <td>175.481270</td>\n",
       "      <td>61.849705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>1196</td>\n",
       "      <td>1</td>\n",
       "      <td>156.435215</td>\n",
       "      <td>237.864104</td>\n",
       "      <td>81.428889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>1202</td>\n",
       "      <td>1</td>\n",
       "      <td>183.692268</td>\n",
       "      <td>252.390907</td>\n",
       "      <td>68.698639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>1213</td>\n",
       "      <td>1</td>\n",
       "      <td>215.053356</td>\n",
       "      <td>288.089977</td>\n",
       "      <td>73.036621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>1214</td>\n",
       "      <td>1</td>\n",
       "      <td>170.906599</td>\n",
       "      <td>242.631678</td>\n",
       "      <td>71.725079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>1236</td>\n",
       "      <td>1</td>\n",
       "      <td>212.114286</td>\n",
       "      <td>280.798912</td>\n",
       "      <td>68.684626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>1263</td>\n",
       "      <td>1</td>\n",
       "      <td>232.663946</td>\n",
       "      <td>315.443084</td>\n",
       "      <td>82.779138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>857</th>\n",
       "      <td>1326</td>\n",
       "      <td>1</td>\n",
       "      <td>134.845215</td>\n",
       "      <td>204.018934</td>\n",
       "      <td>69.173719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>1327</td>\n",
       "      <td>1</td>\n",
       "      <td>89.323152</td>\n",
       "      <td>150.676145</td>\n",
       "      <td>61.352993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>1333</td>\n",
       "      <td>1</td>\n",
       "      <td>106.413560</td>\n",
       "      <td>168.002608</td>\n",
       "      <td>61.589048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902</th>\n",
       "      <td>1341</td>\n",
       "      <td>1</td>\n",
       "      <td>320.614921</td>\n",
       "      <td>487.311995</td>\n",
       "      <td>166.697075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>1356</td>\n",
       "      <td>1</td>\n",
       "      <td>77.775737</td>\n",
       "      <td>138.222018</td>\n",
       "      <td>60.446281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942</th>\n",
       "      <td>1356</td>\n",
       "      <td>1</td>\n",
       "      <td>198.659184</td>\n",
       "      <td>292.220340</td>\n",
       "      <td>93.561156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1087</th>\n",
       "      <td>1403</td>\n",
       "      <td>1</td>\n",
       "      <td>188.556848</td>\n",
       "      <td>252.656327</td>\n",
       "      <td>64.099478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1138</th>\n",
       "      <td>1422</td>\n",
       "      <td>2</td>\n",
       "      <td>60.891179</td>\n",
       "      <td>122.098798</td>\n",
       "      <td>61.207619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1220</th>\n",
       "      <td>1448</td>\n",
       "      <td>1</td>\n",
       "      <td>130.665034</td>\n",
       "      <td>198.610522</td>\n",
       "      <td>67.945488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1313</th>\n",
       "      <td>1492</td>\n",
       "      <td>1</td>\n",
       "      <td>270.897324</td>\n",
       "      <td>350.273016</td>\n",
       "      <td>79.375692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1314</th>\n",
       "      <td>1492</td>\n",
       "      <td>2</td>\n",
       "      <td>24.334467</td>\n",
       "      <td>140.140340</td>\n",
       "      <td>115.805873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1318</th>\n",
       "      <td>1494</td>\n",
       "      <td>1</td>\n",
       "      <td>226.422630</td>\n",
       "      <td>295.886667</td>\n",
       "      <td>69.464036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1322</th>\n",
       "      <td>1495</td>\n",
       "      <td>1</td>\n",
       "      <td>250.582018</td>\n",
       "      <td>320.598503</td>\n",
       "      <td>70.016485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1323</th>\n",
       "      <td>1496</td>\n",
       "      <td>1</td>\n",
       "      <td>52.444399</td>\n",
       "      <td>142.696803</td>\n",
       "      <td>90.252404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1358</th>\n",
       "      <td>229</td>\n",
       "      <td>2</td>\n",
       "      <td>0.426757</td>\n",
       "      <td>76.055646</td>\n",
       "      <td>75.628889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1359</th>\n",
       "      <td>229</td>\n",
       "      <td>2</td>\n",
       "      <td>144.988730</td>\n",
       "      <td>227.382222</td>\n",
       "      <td>82.393492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1362</th>\n",
       "      <td>276</td>\n",
       "      <td>1</td>\n",
       "      <td>10.031020</td>\n",
       "      <td>109.216893</td>\n",
       "      <td>99.185873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437</th>\n",
       "      <td>596</td>\n",
       "      <td>1</td>\n",
       "      <td>13.034580</td>\n",
       "      <td>175.051383</td>\n",
       "      <td>162.016803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1438</th>\n",
       "      <td>596</td>\n",
       "      <td>2</td>\n",
       "      <td>13.028005</td>\n",
       "      <td>87.146735</td>\n",
       "      <td>74.118730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1439</th>\n",
       "      <td>596</td>\n",
       "      <td>2</td>\n",
       "      <td>111.936032</td>\n",
       "      <td>179.452880</td>\n",
       "      <td>67.516848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>884</td>\n",
       "      <td>1</td>\n",
       "      <td>326.960181</td>\n",
       "      <td>396.039546</td>\n",
       "      <td>69.079365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1507</th>\n",
       "      <td>898</td>\n",
       "      <td>1</td>\n",
       "      <td>320.889252</td>\n",
       "      <td>382.455873</td>\n",
       "      <td>61.566621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1531</th>\n",
       "      <td>959</td>\n",
       "      <td>2</td>\n",
       "      <td>582.621111</td>\n",
       "      <td>649.064422</td>\n",
       "      <td>66.443311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1545</th>\n",
       "      <td>967</td>\n",
       "      <td>1</td>\n",
       "      <td>551.506077</td>\n",
       "      <td>622.900930</td>\n",
       "      <td>71.394853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1548</th>\n",
       "      <td>967</td>\n",
       "      <td>2</td>\n",
       "      <td>551.690748</td>\n",
       "      <td>619.276190</td>\n",
       "      <td>67.585442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>984</td>\n",
       "      <td>1</td>\n",
       "      <td>4.997755</td>\n",
       "      <td>76.073946</td>\n",
       "      <td>71.076190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1620</th>\n",
       "      <td>994</td>\n",
       "      <td>1</td>\n",
       "      <td>159.011973</td>\n",
       "      <td>234.800952</td>\n",
       "      <td>75.788980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     song_id annotator  chorus_start  chorus_end  chorus_duration\n",
       "244     1092         1     39.352906  108.064000        68.711094\n",
       "248     1092         2    132.128938  207.033281        74.904344\n",
       "289     1112         1    160.276825  229.602449        69.325624\n",
       "341     1131         1    207.403991  273.851429        66.447438\n",
       "344     1132         1    150.401088  212.810884        62.409796\n",
       "349     1135         1    218.928186  285.362290        66.434104\n",
       "364     1146         1    251.634218  331.775601        80.141383\n",
       "492     1190         1    113.631565  175.481270        61.849705\n",
       "513     1196         1    156.435215  237.864104        81.428889\n",
       "526     1202         1    183.692268  252.390907        68.698639\n",
       "557     1213         1    215.053356  288.089977        73.036621\n",
       "558     1214         1    170.906599  242.631678        71.725079\n",
       "612     1236         1    212.114286  280.798912        68.684626\n",
       "674     1263         1    232.663946  315.443084        82.779138\n",
       "857     1326         1    134.845215  204.018934        69.173719\n",
       "860     1327         1     89.323152  150.676145        61.352993\n",
       "875     1333         1    106.413560  168.002608        61.589048\n",
       "902     1341         1    320.614921  487.311995       166.697075\n",
       "941     1356         1     77.775737  138.222018        60.446281\n",
       "942     1356         1    198.659184  292.220340        93.561156\n",
       "1087    1403         1    188.556848  252.656327        64.099478\n",
       "1138    1422         2     60.891179  122.098798        61.207619\n",
       "1220    1448         1    130.665034  198.610522        67.945488\n",
       "1313    1492         1    270.897324  350.273016        79.375692\n",
       "1314    1492         2     24.334467  140.140340       115.805873\n",
       "1318    1494         1    226.422630  295.886667        69.464036\n",
       "1322    1495         1    250.582018  320.598503        70.016485\n",
       "1323    1496         1     52.444399  142.696803        90.252404\n",
       "1358     229         2      0.426757   76.055646        75.628889\n",
       "1359     229         2    144.988730  227.382222        82.393492\n",
       "1362     276         1     10.031020  109.216893        99.185873\n",
       "1437     596         1     13.034580  175.051383       162.016803\n",
       "1438     596         2     13.028005   87.146735        74.118730\n",
       "1439     596         2    111.936032  179.452880        67.516848\n",
       "1498     884         1    326.960181  396.039546        69.079365\n",
       "1507     898         1    320.889252  382.455873        61.566621\n",
       "1531     959         2    582.621111  649.064422        66.443311\n",
       "1545     967         1    551.506077  622.900930        71.394853\n",
       "1548     967         2    551.690748  619.276190        67.585442\n",
       "1596     984         1      4.997755   76.073946        71.076190\n",
       "1620     994         1    159.011973  234.800952        75.788980"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of songs to check that have chorus duration over a minute\n",
    "chorus_df_dur.loc[chorus_df_dur['chorus_duration'] > 60]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3c0208",
   "metadata": {},
   "source": [
    "## Drop duplicate Choruses from Multiple Annotators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "31f793fa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  song_id annotator  chorus_start  chorus_end  chorus_duration\n",
      "0    1003         2     89.722358  118.502698        28.780340\n",
      "1    1003         1    107.144059  118.560272        11.416213\n",
      "2    1003         1    153.137029  176.392086        23.255057\n",
      "3    1003         2    210.783991  239.428345        28.644354\n",
      "4    1004         1     74.257415  112.743107        38.485692 \n",
      "\n",
      "Number of unique songs: 337 \n",
      "\n",
      "Total number of choruses: 1214\n"
     ]
    }
   ],
   "source": [
    "# Custom function to drop duplicates based on 'chorus_start' and 'chorus_end'\n",
    "def drop_duplicate_choruses(df):\n",
    "    \"\"\"\n",
    "    Deduplicates chorus entries in a DataFrame.\n",
    "    Args:\n",
    "        df (DataFrame): The DataFrame with chorus entries.\n",
    "    Returns:\n",
    "        DataFrame: A DataFrame with deduplicated chorus entries.\n",
    "    \"\"\"\n",
    "    # Avoid directly modifying the original DataFrame\n",
    "    df = df.copy()\n",
    "    # Sort by 'song_id', 'chorus_start', 'chorus_end' to prepare for comparison\n",
    "    df.sort_values(by=['song_id', 'chorus_start', 'chorus_end'], inplace=True)\n",
    "    # Keep track of the rows to keep\n",
    "    rows_to_keep = []\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        if not rows_to_keep:  # If list is empty, add the first row\n",
    "            rows_to_keep.append(row)\n",
    "        else:\n",
    "            # Compare with the last added row\n",
    "            last_row = rows_to_keep[-1]\n",
    "            # Check if both start and end times are within 5 seconds\n",
    "            if (row['song_id'] == last_row['song_id'] and\n",
    "                abs(row['chorus_start'] - last_row['chorus_start']) <= 5 and\n",
    "                abs(row['chorus_end'] - last_row['chorus_end']) <= 5):\n",
    "                continue  # Skip this row as it's a near-duplicate\n",
    "            else:\n",
    "                rows_to_keep.append(row)  # Add unique row\n",
    "\n",
    "    # Return DataFrame of unique rows\n",
    "    return pd.DataFrame(rows_to_keep)\n",
    "\n",
    "# Apply custom deduplication function\n",
    "chorus_df = drop_duplicate_choruses(chorus_df_dur)\n",
    "\n",
    "# Reset index for cleanliness\n",
    "chorus_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(chorus_df.head(), \"\\n\")\n",
    "print('Number of unique songs:', chorus_df['song_id'].nunique(), \"\\n\")\n",
    "print('Total number of choruses:', chorus_df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8072f7ac",
   "metadata": {},
   "source": [
    "## Join metadata.csv and iTunes metadata info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b4ae0d04",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GENRE           0\n",
       "Genre_itunes    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the metadata CSV into a DataFrame and select the relevant columns directly\n",
    "metadata_df = pd.read_csv('../data/external/metadata.csv')[['SONG_ID', 'SONG_TITLE', 'ARTIST', 'CLASS', 'GENRE']]\n",
    "# Convert 'SONG_ID' in metadata_df to categorical dtype\n",
    "metadata_df['SONG_ID'] = metadata_df['SONG_ID'].astype('category')\n",
    "\n",
    "# Assuming 'song_id' needs to be converted to categorical dtype in chorus_df\n",
    "chorus_df['song_id'] = chorus_df['song_id'].astype('category')\n",
    "\n",
    "# Perform the left join on the 'song_id' column from chorus_df and 'SONG_ID' from metadata_df\n",
    "joined_meta = pd.merge(\n",
    "    chorus_df,\n",
    "    metadata_df,\n",
    "    left_on='song_id',                 # 'song_id' from chorus_df\n",
    "    right_on='SONG_ID',                # 'SONG_ID' from metadata_df\n",
    "    how='left'                         # Left join to keep everything from chorus_df\n",
    ")\n",
    "\n",
    "# Drop the 'SONG_ID' column from metadata_df as it's redundant with 'song_id' from chorus_df\n",
    "joined_meta.drop('SONG_ID', axis=1, inplace=True)\n",
    "\n",
    "# Load the itunes data, rename 'Genre' column and perform a second merge\n",
    "itunes_df = pd.read_csv('../data/external/SALAMI_iTunes_library.csv')\n",
    "itunes_df.rename(columns={'Genre': 'Genre_itunes'}, inplace=True)\n",
    "# Ensure that 'salami_id' is also categorical if it's not already\n",
    "itunes_df['salami_id'] = itunes_df['salami_id'].astype('category')\n",
    "\n",
    "# Merge the itunes_df with the joined_df\n",
    "joined_meta_itunes = pd.merge(\n",
    "    joined_meta,\n",
    "    itunes_df[['salami_id', 'Genre_itunes', 'Album']],  # Select only the necessary columns\n",
    "    left_on='song_id',               # 'song_id' from joined_df\n",
    "    right_on='salami_id',            # 'salami_id' from itunes_df\n",
    "    how='left'                       # Left join to keep everything from joined_df\n",
    ")\n",
    "\n",
    "# Drop the 'salami_id' column as it's redundant after the merge\n",
    "joined_meta_itunes.drop('salami_id', axis=1, inplace=True)\n",
    "\n",
    "# Display the first few rows of the final dataframe\n",
    "joined_meta_itunes.head()\n",
    "joined_meta_itunes[['GENRE', 'Genre_itunes']].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ca42e0c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  song_id annotator  chorus_start  chorus_end  chorus_duration    SONG_TITLE  \\\n",
      "0    1003         2     89.722358  118.502698        28.780340  Im_Moving_On   \n",
      "1    1003         1    107.144059  118.560272        11.416213  Im_Moving_On   \n",
      "2    1003         1    153.137029  176.392086        23.255057  Im_Moving_On   \n",
      "3    1003         2    210.783991  239.428345        28.644354  Im_Moving_On   \n",
      "4    1004         1     74.257415  112.743107        38.485692      Fearless   \n",
      "\n",
      "        ARTIST               CLASS GENRE salami_id Genre_itunes Album  \n",
      "0    Big_Water  Live_Music_Archive   NaN       NaN          NaN   NaN  \n",
      "1    Big_Water  Live_Music_Archive   NaN       NaN          NaN   NaN  \n",
      "2    Big_Water  Live_Music_Archive   NaN       NaN          NaN   NaN  \n",
      "3    Big_Water  Live_Music_Archive   NaN       NaN          NaN   NaN  \n",
      "4  Big_Whiskey  Live_Music_Archive   NaN       NaN          NaN   NaN  \n",
      "\n",
      "GENRE                              Genre_itunes                     \n",
      "Country                            Country                              14\n",
      "R_B_-_Gospel                       R&B - Gospel                         10\n",
      "World_-_Balkan                     World - Balkan                       10\n",
      "Humour                             Humour                               10\n",
      "World_-_Klezmer                    World - Klezmer                       9\n",
      "Classical_-_Classical              Classical - Classical                 8\n",
      "Modern_Folk_-_Singer___Songwriter  Modern Folk - Singer / Songwriter     6\n",
      "World_-_U_S__Traditional           World - U.S. Traditional              6\n",
      "Classical_-_Renaissance___Med_     Classical - Renaissance & Med.        6\n",
      "R_B_-_Contemporary_R_B             R&B - Contemporary R&B                4\n",
      "R_B_-_Soul                         R&B - Soul                            4\n",
      "Reggae                             Reggae                                4\n",
      "World_-_African                    World - African                       4\n",
      "World_-_Indian                     World - Indian                        4\n",
      "Rock_-_Alternative_Metal___Punk    Rock - Alternative Metal / Punk       3\n",
      "Alternative_Pop___Rock             Alternative Pop / Rock                3\n",
      "R_B_-_Funk                         R&B - Funk                            2\n",
      "Classical_-_Romantic               Classical - Romantic                  2\n",
      "Classical_-_Baroque                Classical - Baroque                   1\n",
      "World_-_Cuban                      World - Cuban                         1\n",
      "dtype: int64\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1214 entries, 0 to 1213\n",
      "Data columns (total 12 columns):\n",
      " #   Column           Non-Null Count  Dtype   \n",
      "---  ------           --------------  -----   \n",
      " 0   song_id          1214 non-null   category\n",
      " 1   annotator        1214 non-null   category\n",
      " 2   chorus_start     1214 non-null   float64 \n",
      " 3   chorus_end       1214 non-null   float64 \n",
      " 4   chorus_duration  1214 non-null   float64 \n",
      " 5   SONG_TITLE       1214 non-null   object  \n",
      " 6   ARTIST           1214 non-null   object  \n",
      " 7   CLASS            1214 non-null   category\n",
      " 8   GENRE            111 non-null    category\n",
      " 9   salami_id        111 non-null    object  \n",
      " 10  Genre_itunes     111 non-null    category\n",
      " 11  Album            111 non-null    object  \n",
      "dtypes: category(5), float64(3), object(4)\n",
      "memory usage: 95.4+ KB\n",
      "None /n\n"
     ]
    }
   ],
   "source": [
    "# Load the metadata CSV into a DataFrame and select the relevant columns\n",
    "metadata_df = pd.read_csv('../data/external/metadata.csv')[['SONG_ID', 'SONG_TITLE', 'ARTIST', 'CLASS', 'GENRE']]\n",
    "\n",
    "# Convert to strings, perform the filtering, and then convert to categorical if needed\n",
    "metadata_df['SONG_ID'] = metadata_df['SONG_ID'].astype(str)\n",
    "chorus_df['song_id'] = chorus_df['song_id'].astype(str)\n",
    "\n",
    "# Filter metadata_df to only include rows with SONG_ID present in chorus_df's song_id\n",
    "metadata_df_filtered = metadata_df[metadata_df['SONG_ID'].isin(chorus_df['song_id'])]\n",
    "\n",
    "# Merge chorus and metadata \n",
    "joined_meta = pd.merge(\n",
    "    chorus_df,\n",
    "    metadata_df_filtered,\n",
    "    left_on='song_id',\n",
    "    right_on='SONG_ID',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Drop the 'SONG_ID' column \n",
    "joined_meta.drop('SONG_ID', axis=1, inplace=True)\n",
    "\n",
    "# Load the itunes data, rename 'Genre' column and perform a second merge\n",
    "itunes_df = pd.read_csv('../data/external/SALAMI_iTunes_library.csv')\n",
    "itunes_df.rename(columns={'Genre': 'Genre_itunes'}, inplace=True)\n",
    "\n",
    "# Ensure that 'salami_id' is also 'str' \n",
    "itunes_df['salami_id'] = itunes_df['salami_id'].astype('str')\n",
    "\n",
    "# Merge the itunes_df with the joined_df\n",
    "joined_meta_itunes = pd.merge(\n",
    "    joined_meta,\n",
    "    itunes_df[['salami_id', 'Genre_itunes', 'Album']],  # Select only the necessary columns\n",
    "    left_on='song_id',               # 'song_id' from joined_df\n",
    "    right_on='salami_id',            # 'salami_id' from itunes_df\n",
    "    how='left'                       # Left join to keep everything from joined_df\n",
    ")\n",
    "joined_meta_itunes[['song_id', 'annotator', 'CLASS', 'GENRE', 'Genre_itunes']] = joined_meta_itunes[['song_id', 'annotator', 'CLASS', 'GENRE', 'Genre_itunes']].astype('category')\n",
    "\n",
    "print(joined_meta_itunes.head())\n",
    "print()\n",
    "print(joined_meta_itunes[['GENRE', 'Genre_itunes']].value_counts())\n",
    "print()\n",
    "print(joined_meta_itunes.info(),\"/n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "0e518a56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['song_id', 'annotator', 'chorus_start', 'chorus_end', 'chorus_duration',\n",
       "       'SONG_TITLE', 'ARTIST', 'CLASS', 'GENRE', 'salami_id', 'Genre_itunes',\n",
       "       'Album'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_meta_itunes.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "4c37eecc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Save file\n",
    "joined_meta_itunes.to_csv(r'C:\\Users\\denni\\OneDrive\\Desktop\\Springboard\\MusicAnnotator\\data\\chorus_and_metadata.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5d7afb",
   "metadata": {},
   "source": [
    "## Checking anomalies, ydata profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "658a2500",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4e2b15f5dd74ee89e715b22cade2b8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\denni\\anaconda3\\Lib\\site-packages\\scipy\\stats\\_stats_py.py:112: RuntimeWarning: The input array could not be properly checked for nan values. nan values will be ignored.\n",
      "  warnings.warn(\"The input array could not be properly \"\n",
      "C:\\Users\\denni\\anaconda3\\Lib\\site-packages\\scipy\\stats\\_stats_py.py:112: RuntimeWarning: The input array could not be properly checked for nan values. nan values will be ignored.\n",
      "  warnings.warn(\"The input array could not be properly \"\n",
      "C:\\Users\\denni\\anaconda3\\Lib\\site-packages\\scipy\\stats\\_stats_py.py:112: RuntimeWarning: The input array could not be properly checked for nan values. nan values will be ignored.\n",
      "  warnings.warn(\"The input array could not be properly \"\n",
      "C:\\Users\\denni\\anaconda3\\Lib\\site-packages\\scipy\\stats\\_stats_py.py:112: RuntimeWarning: The input array could not be properly checked for nan values. nan values will be ignored.\n",
      "  warnings.warn(\"The input array could not be properly \"\n",
      "C:\\Users\\denni\\anaconda3\\Lib\\site-packages\\scipy\\stats\\_stats_py.py:112: RuntimeWarning: The input array could not be properly checked for nan values. nan values will be ignored.\n",
      "  warnings.warn(\"The input array could not be properly \"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39336fb44de7441fb2bf3bd41291fa6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbdd3264157a4dfca48191a6098f2e69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Render HTML:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adc3fecea65f4614ab417bbaa0614234",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Export report to file:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1000\"\n",
       "            height=\"1600\"\n",
       "            src=\"wrangling_report.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1e5dc567e50>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profile = ProfileReport(joined_meta_itunes, title='Pandas Profiling Report', explorative=True)\n",
    "\n",
    "# Save the profile report to a file\n",
    "profile.to_file(\"wrangling_report.html\")\n",
    "\n",
    "# Display the profile in an iframe with custom width and height\n",
    "IFrame(src='wrangling_report.html', width=1000, height=1600)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
