{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "883b906b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import ttest_rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a17af220-66f6-4191-a19e-72439e1d9168",
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_tempo(tempo):\n",
    "    \"\"\"Rounds the tempo to the nearest whole number with a small tolerance for deviation.\"\"\"\n",
    "    rounded_tempo = round(tempo)\n",
    "    if abs(tempo - rounded_tempo) <= 0.2:\n",
    "        return rounded_tempo\n",
    "    else:\n",
    "        return int(tempo)\n",
    "\n",
    "\n",
    "def create_beat_grid(onset_frames, sr, beat_interval_in_frames, time_signature, duration):\n",
    "    \"\"\"Creates a grid of measures based on the tempo, time signature, and beats of the song.\"\"\"\n",
    "\n",
    "    tolerance_in_seconds = 0.1\n",
    "    tolerance_in_frames = int(librosa.time_to_frames(tolerance_in_seconds, sr=sr))\n",
    "\n",
    "    # Convert duration from seconds to frames\n",
    "    duration_in_frames = librosa.time_to_frames(duration, sr=sr)\n",
    "\n",
    "    # Find valid beat sequences\n",
    "    valid_sequences = []\n",
    "    current_sequence = []\n",
    "    min_sequence_length = 4\n",
    "    for i in range(len(onset_frames) - 1):\n",
    "        frame_diff = onset_frames[i + 1] - onset_frames[i]\n",
    "        if abs(frame_diff - beat_interval_in_frames) <= tolerance_in_frames:\n",
    "            if not current_sequence:\n",
    "                current_sequence = [onset_frames[i]]\n",
    "            current_sequence.append(onset_frames[i + 1])\n",
    "        else:\n",
    "            if current_sequence and len(current_sequence) >= min_sequence_length:\n",
    "                valid_sequences.append(current_sequence)\n",
    "            current_sequence = []\n",
    "    if current_sequence and len(current_sequence) >= min_sequence_length:\n",
    "        valid_sequences.append(current_sequence)\n",
    "\n",
    "    # If no valid sequences are found, start a grid search\n",
    "    while not valid_sequences and tolerance_in_seconds < 0.5 and min_sequence_length > 1:\n",
    "        tolerance_in_seconds += 0.1\n",
    "        tolerance_in_frames = int(librosa.time_to_frames(tolerance_in_seconds, sr=sr))\n",
    "        min_sequence_length -= 1\n",
    "        valid_sequences = []\n",
    "        current_sequence = []\n",
    "        for i in range(len(onset_frames) - 1):\n",
    "            frame_diff = onset_frames[i + 1] - onset_frames[i]\n",
    "            if abs(frame_diff - beat_interval_in_frames) <= tolerance_in_frames:\n",
    "                if not current_sequence:\n",
    "                    current_sequence = [onset_frames[i]]\n",
    "                current_sequence.append(onset_frames[i + 1])\n",
    "            else:\n",
    "                if current_sequence and len(current_sequence) >= min_sequence_length:\n",
    "                    valid_sequences.append(current_sequence)\n",
    "                current_sequence = []\n",
    "        if current_sequence and len(current_sequence) >= min_sequence_length:\n",
    "            valid_sequences.append(current_sequence)\n",
    "\n",
    "    # Set the anchor frame to the first onset if no valid sequences are found\n",
    "    if not valid_sequences:\n",
    "        anchor_frame = onset_frames[0]\n",
    "    else:\n",
    "        first_sequence = valid_sequences[0]\n",
    "        anchor_frame = first_sequence[0]\n",
    "\n",
    "    # Add beats before the first onset (working backwards)\n",
    "    beat_grid = [anchor_frame]\n",
    "    current_frame = anchor_frame\n",
    "    while current_frame >= 0:\n",
    "        current_frame -= beat_interval_in_frames\n",
    "        beat_grid.insert(0, current_frame)\n",
    "\n",
    "    # Remove the first beat if it's negative\n",
    "    if beat_grid[0] < 0:\n",
    "        beat_grid.pop(0)\n",
    "\n",
    "    # Add beats after the anchor frame\n",
    "    current_frame = anchor_frame + beat_interval_in_frames\n",
    "    while current_frame <= duration_in_frames:\n",
    "        beat_grid.append(current_frame)\n",
    "        current_frame += beat_interval_in_frames \n",
    "    # Group beats into measures\n",
    "    measure_grid = []\n",
    "    current_frame = beat_grid[0]\n",
    "    while current_frame <= duration_in_frames:\n",
    "        measure_grid.append(current_frame)\n",
    "        current_frame += beat_interval_in_frames * time_signature\n",
    "    \n",
    "    return np.array(beat_grid), np.array(measure_grid)\n",
    "\n",
    "\n",
    "def calculate_distances(start_frame, end_frame, beat_grid, measure_grid):\n",
    "    \"\"\"Calculate distances from the closest beat and measure for chorus start and end times.\"\"\"\n",
    "    \n",
    "    # Initialize a dictionary to store distances\n",
    "    distances = {\n",
    "        'start_to_nearest_beat': None,\n",
    "        'end_to_nearest_beat': None,\n",
    "        'start_to_nearest_measure': None,\n",
    "        'end_to_nearest_measure': None\n",
    "    }\n",
    "    \n",
    "    # Find the closest beat to the chorus start and end times\n",
    "    closest_start_beat_index = np.argmin(np.abs(beat_grid - start_frame))\n",
    "    closest_end_beat_index = np.argmin(np.abs(beat_grid - end_frame))\n",
    "    \n",
    "    # Find the closest measure to the chorus start and end times\n",
    "    closest_start_measure_index = np.argmin(np.abs(measure_grid - start_frame))\n",
    "    closest_end_measure_index = np.argmin(np.abs(measure_grid - end_frame))\n",
    "    \n",
    "    # Calculate the distances from the chorus start to the nearest beat and measure\n",
    "    distances['start_to_nearest_beat'] = (beat_grid[closest_start_beat_index] - start_frame)/48000\n",
    "    distances['start_to_nearest_measure'] = (measure_grid[closest_start_measure_index] - start_frame)/48000\n",
    "    \n",
    "    # Calculate the distances from the chorus end to the nearest beat and measure\n",
    "    distances['end_to_nearest_beat'] = (beat_grid[closest_end_beat_index] - end_frame)/48000\n",
    "    distances['end_to_nearest_measure'] = (measure_grid[closest_end_measure_index] - end_frame)/48000\n",
    "    \n",
    "    return distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "170b777d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa17a20022f94aeaa1c80b30390e9271",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing:   0%|          | 0/332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the DataFrame with labeled data\n",
    "df = pd.read_csv('../data/dataframes/clean_labeled.csv')\n",
    "\n",
    "# Initialize an empty DataFrame for the results\n",
    "results_df = pd.DataFrame()\n",
    "\n",
    "# Iterate through the DataFrame and prepare data for each song\n",
    "for _, group in tqdm(df.groupby('SongID'), desc='Processing'):\n",
    "    song_id = group['SongID'].values[0]\n",
    "    audio_path = group['FilePath'].values[0]\n",
    "    y, sr = librosa.load(audio_path, sr=None)\n",
    "\n",
    "    # Extract tempo, beat frames, and time signature\n",
    "    C = np.abs(librosa.cqt(y=y, sr=sr))\n",
    "    onset_env = librosa.onset.onset_strength(sr=sr, S=librosa.amplitude_to_db(C, ref=np.max))\n",
    "    tempo, _ = librosa.beat.beat_track(onset_envelope=onset_env, sr=sr)\n",
    "    sp_tempo = group['sp_tempo'].values[0] if not pd.isna(group['sp_tempo'].values[0]) else tempo\n",
    "    if sp_tempo == 0:\n",
    "        sp_tempo = tempo\n",
    "    if sp_tempo > 142:\n",
    "        sp_tempo /= 2\n",
    "    if sp_tempo < 71:\n",
    "        sp_tempo *= 2\n",
    "    tempo = round_tempo(sp_tempo)\n",
    "\n",
    "    time_signature = group['sp_time_signature'].values[0] if not pd.isna(group['sp_time_signature'].values[0]) else 4\n",
    "    time_signature = int(time_signature) if time_signature != 0 else 4\n",
    "\n",
    "    # Create a measure grid\n",
    "    duration = librosa.get_duration(y=y, sr=sr)\n",
    "    onset_frames = librosa.onset.onset_detect(onset_envelope=onset_env, sr=sr, backtrack=True, units='frames')\n",
    "    beat_interval_in_seconds = 60 / tempo\n",
    "    beat_interval_in_frames = int(librosa.time_to_frames(beat_interval_in_seconds, sr=sr))\n",
    "    beat_grid, measure_grid = create_beat_grid(onset_frames, sr, beat_interval_in_frames, time_signature, duration)\n",
    "    # Iterate through each chorus in the group\n",
    "    for _, chorus in group.iterrows():\n",
    "        if chorus['label'] == 'chorus':\n",
    "            start_frame = chorus['start_frame']\n",
    "            end_frame = chorus['end_frame']\n",
    "    \n",
    "            # Call the function to calculate distances\n",
    "            distances = calculate_distances(start_frame, end_frame, beat_grid, measure_grid)\n",
    "            \n",
    "            # Create a DataFrame from the distances dictionary\n",
    "            distances_df = pd.DataFrame([distances])\n",
    "    \n",
    "            # Add the SongID and other relevant information to the distances DataFrame\n",
    "            distances_df['SongID'] = song_id  # <-- SongID is added here\n",
    "            distances_df['start_frame'] = start_frame\n",
    "            distances_df['end_frame'] = end_frame\n",
    "    \n",
    "            # Append the result to the results DataFrame\n",
    "            results_df = pd.concat([results_df, distances_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9a169097-f741-46fb-99c2-ac6dc4d6e7a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Distances (absolute values):\n",
      "start_to_nearest_beat       0.000771\n",
      "end_to_nearest_beat         0.027187\n",
      "start_to_nearest_measure    0.002104\n",
      "end_to_nearest_measure      0.027187\n",
      "dtype: float64\n",
      "\n",
      "Average Distances (absolute values):\n",
      "start_to_nearest_beat       0.000213\n",
      "end_to_nearest_beat         0.000278\n",
      "start_to_nearest_measure    0.000823\n",
      "end_to_nearest_measure      0.000906\n",
      "dtype: float64\n",
      "\n",
      "Standard Deviations (absolute values):\n",
      "start_to_nearest_beat       0.000140\n",
      "end_to_nearest_beat         0.001259\n",
      "start_to_nearest_measure    0.000568\n",
      "end_to_nearest_measure      0.001338\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Apply the absolute value function to the columns\n",
    "results_df_abs = results_df[['start_to_nearest_beat', 'end_to_nearest_beat',\n",
    "                             'start_to_nearest_measure', 'end_to_nearest_measure']].abs()\n",
    "\n",
    "# Calculate the maximum, average, and standard deviation of the absolute values\n",
    "max_distances = results_df_abs.max()\n",
    "average_distances = results_df_abs.mean()\n",
    "std_distances = results_df_abs.std()\n",
    "\n",
    "# Output the calculated metrics\n",
    "print(\"Maximum Distances (absolute values):\")\n",
    "print(max_distances)\n",
    "print(\"\\nAverage Distances (absolute values):\")\n",
    "print(average_distances)\n",
    "print(\"\\nStandard Deviations (absolute values):\")\n",
    "print(std_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d7db94d8-b148-40e7-a218-6f2d0bf70056",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5493d9ea5e9404fa97f49eba61e9fd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing:   0%|          | 0/332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test using CQT generated tempo with rounding\n",
    "# Initialize an empty DataFrame for the results\n",
    "CQT_results_df = pd.DataFrame()\n",
    "\n",
    "# Iterate through the DataFrame and prepare data for each song\n",
    "for _, group in tqdm(df.groupby('SongID'), desc='Processing'):\n",
    "    song_id = group['SongID'].values[0]\n",
    "    audio_path = group['FilePath'].values[0]\n",
    "    y, sr = librosa.load(audio_path, sr=None)\n",
    "\n",
    "    # Extract tempo, beat frames, and time signature\n",
    "    C = np.abs(librosa.cqt(y=y, sr=sr))\n",
    "    onset_env = librosa.onset.onset_strength(sr=sr, S=librosa.amplitude_to_db(C, ref=np.max))\n",
    "    tempo, _ = librosa.beat.beat_track(onset_envelope=onset_env, sr=sr)\n",
    "    if tempo >= 140:\n",
    "        tempo /= 2\n",
    "    if tempo < 70:\n",
    "        tempo *= 2\n",
    "    tempo = round_tempo(tempo)\n",
    "\n",
    "    time_signature = group['sp_time_signature'].values[0] if not pd.isna(group['sp_time_signature'].values[0]) else 4\n",
    "    time_signature = int(time_signature) if time_signature != 0 else 4\n",
    "\n",
    "    # Create a measure grid\n",
    "    duration = librosa.get_duration(y=y, sr=sr)\n",
    "    onset_frames = librosa.onset.onset_detect(onset_envelope=onset_env, sr=sr, backtrack=True, units='frames')\n",
    "    beat_interval_in_seconds = 60 / tempo\n",
    "    beat_interval_in_frames = int(librosa.time_to_frames(beat_interval_in_seconds, sr=sr))\n",
    "    beat_grid, measure_grid = create_beat_grid(onset_frames, sr, beat_interval_in_frames, time_signature, duration)\n",
    "    # Iterate through each chorus in the group\n",
    "    for _, chorus in group.iterrows():\n",
    "        if chorus['label'] == 'chorus':\n",
    "            start_frame = chorus['start_frame']\n",
    "            end_frame = chorus['end_frame']\n",
    "    \n",
    "            # Call the function to calculate distances\n",
    "            distances = calculate_distances(start_frame, end_frame, beat_grid, measure_grid)\n",
    "            \n",
    "            # Create a DataFrame from the distances dictionary\n",
    "            distances_df = pd.DataFrame([distances])\n",
    "    \n",
    "            # Add the SongID and other relevant information to the distances DataFrame\n",
    "            distances_df['SongID'] = song_id  # <-- SongID is added here\n",
    "            distances_df['start_frame'] = start_frame\n",
    "            distances_df['end_frame'] = end_frame\n",
    "    \n",
    "            # Append the result to the results DataFrame\n",
    "            CQT_results_df = pd.concat([CQT_results_df, distances_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2be2f851-f902-4892-bdf8-31f33cdd227d",
   "metadata": {},
   "outputs": [],
   "source": [
    "CQT_results_df_abs = CQT_results_df[['start_to_nearest_beat', 'end_to_nearest_beat',\n",
    "                             'start_to_nearest_measure', 'end_to_nearest_measure']].abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ae6fd368-d50a-476f-a40b-cc50be678bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column: start_to_nearest_beat\n",
      "Paired t-test Statistics=-1.2613135564488143, p-value=0.20759176544825514\n",
      "Mean difference: -6.244399641577062e-06\n",
      "For column start_to_nearest_beat, there is no significant difference between the first test and the second test (p >= 0.05).\n",
      "\n",
      "Column: end_to_nearest_beat\n",
      "Paired t-test Statistics=-1.331718153686073, p-value=0.18336120874160272\n",
      "Mean difference: -7.308467741935485e-06\n",
      "For column end_to_nearest_beat, there is no significant difference between the first test and the second test (p >= 0.05).\n",
      "\n",
      "Column: start_to_nearest_measure\n",
      "Paired t-test Statistics=-4.3583770200923615, p-value=1.4948498165870041e-05\n",
      "Mean difference: -8.459341397849463e-05\n",
      "For column start_to_nearest_measure, the differences are statistically significant, and the mean difference (-8.459341397849463e-05) suggests that the first test has smaller distances on average compared to the second test (p < 0.05).\n",
      "\n",
      "Column: end_to_nearest_measure\n",
      "Paired t-test Statistics=-2.1531478694669763, p-value=0.031628248501897924\n",
      "Mean difference: -4.026657706093189e-05\n",
      "For column end_to_nearest_measure, the differences are statistically significant, and the mean difference (-4.026657706093189e-05) suggests that the first test has smaller distances on average compared to the second test (p < 0.05).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Column names to test\n",
    "columns_to_test = [\n",
    "    'start_to_nearest_beat', 'end_to_nearest_beat',\n",
    "    'start_to_nearest_measure', 'end_to_nearest_measure'\n",
    "]\n",
    "\n",
    "# Loop over each column and perform the paired t-test\n",
    "for column in columns_to_test:\n",
    "    # Calculate the differences\n",
    "    differences = results_df_abs[column] - CQT_results_df_abs[column]\n",
    "    \n",
    "    # Calculate the mean difference\n",
    "    mean_difference = differences.mean()\n",
    "    \n",
    "    # Calculate the t-statistic and the p-value\n",
    "    t_stat, p_value = ttest_rel(results_df_abs[column], CQT_results_df_abs[column])\n",
    "    \n",
    "    print(f'Column: {column}')\n",
    "    print(f'Paired t-test Statistics={t_stat}, p-value={p_value}')\n",
    "    print(f'Mean difference: {mean_difference}')\n",
    "    \n",
    "    # Interpretation based on a standard alpha value of 0.05\n",
    "    alpha = 0.05\n",
    "    if p_value < alpha:\n",
    "        direction = \"smaller\" if mean_difference < 0 else \"larger\"\n",
    "        print(f'For column {column}, the differences are statistically significant, and the mean difference ({mean_difference}) suggests that the first test has {direction} distances on average compared to the second test (p < {alpha}).\\n')\n",
    "    else:\n",
    "        print(f'For column {column}, there is no significant difference between the first test and the second test (p >= {alpha}).\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9ea2a2f1-9391-4ebd-88aa-5663ae901cd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "452d4134d56743a2b7f88706aa15e656",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing:   0%|          | 0/332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test using CQT generated tempo with no rounding\n",
    "# Initialize an empty DataFrame for the results\n",
    "CQT_no_round_results_df = pd.DataFrame()\n",
    "\n",
    "# Iterate through the DataFrame and prepare data for each song\n",
    "for _, group in tqdm(df.groupby('SongID'), desc='Processing'):\n",
    "    song_id = group['SongID'].values[0]\n",
    "    audio_path = group['FilePath'].values[0]\n",
    "    y, sr = librosa.load(audio_path, sr=None)\n",
    "\n",
    "    # Extract tempo, beat frames, and time signature\n",
    "    C = np.abs(librosa.cqt(y=y, sr=sr))\n",
    "    onset_env = librosa.onset.onset_strength(sr=sr, S=librosa.amplitude_to_db(C, ref=np.max))\n",
    "    tempo, _ = librosa.beat.beat_track(onset_envelope=onset_env, sr=sr)\n",
    "    if tempo >= 140:\n",
    "        tempo /= 2\n",
    "    if tempo < 70:\n",
    "        tempo *= 2\n",
    "\n",
    "    time_signature = group['sp_time_signature'].values[0] if not pd.isna(group['sp_time_signature'].values[0]) else 4\n",
    "    time_signature = int(time_signature) if time_signature != 0 else 4\n",
    "\n",
    "    # Create a measure grid\n",
    "    duration = librosa.get_duration(y=y, sr=sr)\n",
    "    onset_frames = librosa.onset.onset_detect(onset_envelope=onset_env, sr=sr, backtrack=True, units='frames')\n",
    "    beat_interval_in_seconds = 60 / tempo\n",
    "    beat_interval_in_frames = int(librosa.time_to_frames(beat_interval_in_seconds, sr=sr))\n",
    "    beat_grid, measure_grid = create_beat_grid(onset_frames, sr, beat_interval_in_frames, time_signature, duration)\n",
    "    # Iterate through each chorus in the group\n",
    "    for _, chorus in group.iterrows():\n",
    "        if chorus['label'] == 'chorus':\n",
    "            start_frame = chorus['start_frame']\n",
    "            end_frame = chorus['end_frame']\n",
    "    \n",
    "            # Call the function to calculate distances\n",
    "            distances = calculate_distances(start_frame, end_frame, beat_grid, measure_grid)\n",
    "            \n",
    "            # Create a DataFrame from the distances dictionary\n",
    "            distances_df = pd.DataFrame([distances])\n",
    "    \n",
    "            # Add the SongID and other relevant information to the distances DataFrame\n",
    "            distances_df['SongID'] = song_id  # <-- SongID is added here\n",
    "            distances_df['start_frame'] = start_frame\n",
    "            distances_df['end_frame'] = end_frame\n",
    "    \n",
    "            # Append the result to the results DataFrame\n",
    "            CQT_no_round_results_df = pd.concat([CQT_no_round_results_df, distances_df], ignore_index=True)\n",
    "            \n",
    "CQT_no_round_results_df_abs = CQT_no_round_results_df[['start_to_nearest_beat', 'end_to_nearest_beat',\n",
    "                             'start_to_nearest_measure', 'end_to_nearest_measure']].abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2b4b33d4-09b7-470c-be31-08a1d183ef6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column: start_to_nearest_beat\n",
      "Paired t-test Statistics=-0.5201521700463505, p-value=0.6031124624355765\n",
      "Mean difference: -2.0441308243727593e-06\n",
      "For column start_to_nearest_beat, there is no significant difference between the first test and the second test (p >= 0.05).\n",
      "\n",
      "Column: end_to_nearest_beat\n",
      "Paired t-test Statistics=-0.7160344256504535, p-value=0.47419506720599003\n",
      "Mean difference: -2.548163082437276e-06\n",
      "For column end_to_nearest_beat, there is no significant difference between the first test and the second test (p >= 0.05).\n",
      "\n",
      "Column: start_to_nearest_measure\n",
      "Paired t-test Statistics=-2.72367622892034, p-value=0.00660757340987553\n",
      "Mean difference: -4.004256272401434e-05\n",
      "For column start_to_nearest_measure, the differences are statistically significant, and the mean difference (-4.004256272401434e-05) suggests that the first test has smaller distances on average compared to the second test (p < 0.05).\n",
      "\n",
      "Column: end_to_nearest_measure\n",
      "Paired t-test Statistics=-0.18171084835540993, p-value=0.8558592124337043\n",
      "Mean difference: -2.4641577060931916e-06\n",
      "For column end_to_nearest_measure, there is no significant difference between the first test and the second test (p >= 0.05).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Loop over each column and perform the paired t-test\n",
    "for column in columns_to_test:\n",
    "    # Calculate the differences\n",
    "    differences = CQT_no_round_results_df_abs[column] - CQT_results_df_abs[column]\n",
    "    \n",
    "    # Calculate the mean difference\n",
    "    mean_difference = differences.mean()\n",
    "    \n",
    "    # Calculate the t-statistic and the p-value\n",
    "    t_stat, p_value = ttest_rel(CQT_no_round_results_df_abs[column], CQT_results_df_abs[column])\n",
    "    \n",
    "    print(f'Column: {column}')\n",
    "    print(f'Paired t-test Statistics={t_stat}, p-value={p_value}')\n",
    "    print(f'Mean difference: {mean_difference}')\n",
    "    \n",
    "    # Interpretation based on a standard alpha value of 0.05\n",
    "    alpha = 0.05\n",
    "    if p_value < alpha:\n",
    "        direction = \"smaller\" if mean_difference < 0 else \"larger\"\n",
    "        print(f'For column {column}, the differences are statistically significant, and the mean difference ({mean_difference}) suggests that the first test has {direction} distances on average compared to the second test (p < {alpha}).\\n')\n",
    "    else:\n",
    "        print(f'For column {column}, there is no significant difference between the first test and the second test (p >= {alpha}).\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a0f11ef9-ff42-4d5f-9073-9e2396499540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06ece6885fea486da30b91b2cc30548b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing:   0%|          | 0/332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test using CQT generated tempo with no rounding no backtracking\n",
    "# Initialize an empty DataFrame for the results\n",
    "CQT_no_backtrack_results_df = pd.DataFrame()\n",
    "\n",
    "# Iterate through the DataFrame and prepare data for each song\n",
    "for _, group in tqdm(df.groupby('SongID'), desc='Processing'):\n",
    "    song_id = group['SongID'].values[0]\n",
    "    audio_path = group['FilePath'].values[0]\n",
    "    y, sr = librosa.load(audio_path, sr=None)\n",
    "\n",
    "    # Extract tempo, beat frames, and time signature\n",
    "    C = np.abs(librosa.cqt(y=y, sr=sr))\n",
    "    onset_env = librosa.onset.onset_strength(sr=sr, S=librosa.amplitude_to_db(C, ref=np.max))\n",
    "    tempo, _ = librosa.beat.beat_track(onset_envelope=onset_env, sr=sr)\n",
    "    if tempo >= 140:\n",
    "        tempo /= 2\n",
    "    if tempo < 70:\n",
    "        tempo *= 2\n",
    "\n",
    "    time_signature = group['sp_time_signature'].values[0] if not pd.isna(group['sp_time_signature'].values[0]) else 4\n",
    "    time_signature = int(time_signature) if time_signature != 0 else 4\n",
    "\n",
    "    # Create a measure grid\n",
    "    duration = librosa.get_duration(y=y, sr=sr)\n",
    "    onset_frames = librosa.onset.onset_detect(onset_envelope=onset_env, sr=sr, units='frames')\n",
    "    beat_interval_in_seconds = 60 / tempo\n",
    "    beat_interval_in_frames = int(librosa.time_to_frames(beat_interval_in_seconds, sr=sr))\n",
    "    beat_grid, measure_grid = create_beat_grid(onset_frames, sr, beat_interval_in_frames, time_signature, duration)\n",
    "    # Iterate through each chorus in the group\n",
    "    for _, chorus in group.iterrows():\n",
    "        if chorus['label'] == 'chorus':\n",
    "            start_frame = chorus['start_frame']\n",
    "            end_frame = chorus['end_frame']\n",
    "    \n",
    "            # Call the function to calculate distances\n",
    "            distances = calculate_distances(start_frame, end_frame, beat_grid, measure_grid)\n",
    "            \n",
    "            # Create a DataFrame from the distances dictionary\n",
    "            distances_df = pd.DataFrame([distances])\n",
    "    \n",
    "            # Add the SongID and other relevant information to the distances DataFrame\n",
    "            distances_df['SongID'] = song_id  # <-- SongID is added here\n",
    "            distances_df['start_frame'] = start_frame\n",
    "            distances_df['end_frame'] = end_frame\n",
    "    \n",
    "            # Append the result to the results DataFrame\n",
    "            CQT_no_backtrack_results_df = pd.concat([CQT_no_backtrack_results_df, distances_df], ignore_index=True)\n",
    "            \n",
    "CQT_no_backtrack_results_df_abs = CQT_no_backtrack_results_df[['start_to_nearest_beat', 'end_to_nearest_beat',\n",
    "                             'start_to_nearest_measure', 'end_to_nearest_measure']].abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5aad291d-c047-4400-8052-9b62fc18d9f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column: start_to_nearest_beat\n",
      "Paired t-test Statistics=-0.5090298219252374, p-value=0.6108824478586004\n",
      "Mean difference: -1.6521057347670257e-06\n",
      "For column start_to_nearest_beat, there is no significant difference between the first test and the second test (p >= 0.05).\n",
      "\n",
      "Column: end_to_nearest_beat\n",
      "Paired t-test Statistics=1.115701727913295, p-value=0.2649105399980171\n",
      "Mean difference: 4.1722670250896025e-06\n",
      "For column end_to_nearest_beat, there is no significant difference between the first test and the second test (p >= 0.05).\n",
      "\n",
      "Column: start_to_nearest_measure\n",
      "Paired t-test Statistics=-0.6963597039455548, p-value=0.48642137205206526\n",
      "Mean difference: -5.852374551971323e-06\n",
      "For column start_to_nearest_measure, there is no significant difference between the first test and the second test (p >= 0.05).\n",
      "\n",
      "Column: end_to_nearest_measure\n",
      "Paired t-test Statistics=3.0602630818016516, p-value=0.0022910071889945113\n",
      "Mean difference: 3.830645161290323e-05\n",
      "For column end_to_nearest_measure, the differences are statistically significant, and the mean difference (3.830645161290323e-05) suggests that the first test has larger distances on average compared to the second test (p < 0.05).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Loop over each column and perform the paired t-test\n",
    "for column in columns_to_test:\n",
    "    # Calculate the differences\n",
    "    differences = CQT_no_backtrack_results_df_abs[column] - CQT_no_round_results_df_abs[column]\n",
    "    \n",
    "    # Calculate the mean difference\n",
    "    mean_difference = differences.mean()\n",
    "    \n",
    "    # Calculate the t-statistic and the p-value\n",
    "    t_stat, p_value = ttest_rel(CQT_no_backtrack_results_df_abs[column], CQT_no_round_results_df_abs[column])\n",
    "    \n",
    "    print(f'Column: {column}')\n",
    "    print(f'Paired t-test Statistics={t_stat}, p-value={p_value}')\n",
    "    print(f'Mean difference: {mean_difference}')\n",
    "    \n",
    "    # Interpretation based on a standard alpha value of 0.05\n",
    "    alpha = 0.05\n",
    "    if p_value < alpha:\n",
    "        direction = \"smaller\" if mean_difference < 0 else \"larger\"\n",
    "        print(f'For column {column}, the differences are statistically significant, and the mean difference ({mean_difference}) suggests that the first test has {direction} distances on average compared to the second test (p < {alpha}).\\n')\n",
    "    else:\n",
    "        print(f'For column {column}, there is no significant difference between the first test and the second test (p >= {alpha}).\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20025c6f-d9bb-41cf-b6d7-ce9b8df2b14f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'group' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mgroup\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'group' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa089ea-68a1-4be1-ab21-6d4ec94c8248",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
